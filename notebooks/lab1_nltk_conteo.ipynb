{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [
    {
     "data": {
      "text/plain": "['[', 'Moby', 'Dick', 'by', 'Herman']"
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nltk\n",
    "nltk.data.path = [str(Path().resolve().parent.joinpath(\"nltk_data\"))]\n",
    "from nltk.book import text1,text7\n",
    "\n",
    "text1.tokens[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "data": {
      "text/plain": "['Pierre', 'Vinken', ',', '61', 'years']"
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7.tokens[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "nltk.book.texts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "data": {
      "text/plain": "84"
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"Moby\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "data": {
      "text/plain": "['The', 'cat', 'sat', 'on', 'the', 'mat', '.']"
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "mysent = \"The cat sat on the mat.\"\n",
    "mysent_tokens =\tword_tokenize(mysent)\n",
    "mysent_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mysent_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(18, 22), match='leng'>"
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import re\n",
    "\n",
    "m = re.search(\"leng\", \"procesamiento del lenguaje natural\")\n",
    "m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.end()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 7), match='procesa'>"
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = re.search(\"procesa\", \"procesamiento del lenguaje natural\")\n",
    "type(n)\n",
    "n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [
    {
     "data": {
      "text/plain": "['The', 'cat', 'sat', 'on', 'the', 'mat']"
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysent_tokens_nopunct = [word for word in word_tokenize(mysent) if re.search(\"\\w\", word)]\n",
    "mysent_tokens_nopunct"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mysent_tokens_nopunct)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "{'The', 'cat', 'mat', 'on', 'sat', 'the'}"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mysent_tokens_nopunct)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cat', 'mat', 'on', 'sat', 'the'}"
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(word.lower() for word in mysent_tokens_nopunct)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "outputs": [
    {
     "data": {
      "text/plain": "['moby', 'dick', 'by', 'herman', 'melville']"
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick_tokens = text1.tokens\n",
    "moby_dick_tokens_nopunct = [word.lower() for word in moby_dick_tokens if re.search(\"\\w\", word)]\n",
    "moby_dick_tokens_nopunct[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1: Numero de tokens en Moby Dick"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [
    {
     "data": {
      "text/plain": "218621"
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_moby_dick_tokens = len(moby_dick_tokens_nopunct)\n",
    "n_moby_dick_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2: Numero de types en Mobi Dick"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "data": {
      "text/plain": "17140"
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_moby_dick_types = len(set(moby_dick_tokens_nopunct))\n",
    "n_moby_dick_types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3: El type-token ratio de Moby Dick"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "data": {
      "text/plain": "0.07840051962071347"
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_token_ratio = n_moby_dick_types / n_moby_dick_tokens\n",
    "type_token_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4: El type-token ratio de WSJ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "outputs": [
    {
     "data": {
      "text/plain": "0.129748424801388"
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj_tokens = text7.tokens\n",
    "wsj_tokens_nopunct = [word.lower() for word in wsj_tokens if re.search(\"\\w\", word)]\n",
    "n_tokens_in_wsj = len(wsj_tokens_nopunct)\n",
    "n_types_in_wsj = len(set(wsj_tokens_nopunct))\n",
    "wsj_token_ratio = n_types_in_wsj / n_tokens_in_wsj\n",
    "wsj_token_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6: Maximun Likelihood Estimate (MLE) de la palabra \"whale\" en corpus de Moby Dick"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [
    {
     "data": {
      "text/plain": "0.005607878474620462"
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whale_tokens_in_moby_dick = [word for word in moby_dick_tokens_nopunct if word == \"whale\"]\n",
    "n_whale_tokens_in_moby_dick = len(whale_tokens_in_moby_dick)\n",
    "moby_dick_mle_whale = n_whale_tokens_in_moby_dick / n_moby_dick_tokens\n",
    "moby_dick_mle_whale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7: Maximun Likelihood Estimate (MLE) de la palabra “whale” en corpuse de WSJ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whale_tokens_in_wsj = [word for word in wsj_tokens_nopunct if word == \"whale\"]\n",
    "n_whale_tokens_in_wsj = len(whale_tokens_in_wsj)\n",
    "wsj_mle_whale = n_whale_tokens_in_wsj / n_tokens_in_wsj\n",
    "wsj_mle_whale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}