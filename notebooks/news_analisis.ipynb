{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'happytransformer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhappytransformer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HappyTextClassification\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataclasses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataclass\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Callable\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'happytransformer'"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextClassification\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from pathlib import Path\n",
    "from newsapi import NewsApiClient\n",
    "from datetime import date, timedelta\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "import asyncio\n",
    "\n",
    "nltk.data.path = [str(Path().resolve().parent.joinpath(\"nltk_data\"))]\n",
    "\n",
    "# nltk.download(\"punkt\", download_dir=\"./nltk_data\")\n",
    "\n",
    "@dataclass\n",
    "class Digest:\n",
    "    html: str\n",
    "    authors: str\n",
    "    publish_date: str\n",
    "    keywords: str\n",
    "    summary: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "def process_article(article: Article) -> Callable:\n",
    "    def _process_article() -> Digest:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        return Digest(\n",
    "            html=article.html,\n",
    "            authors=article.authors,\n",
    "            publish_date=article.publish_date,\n",
    "            keywords=article.keywords,\n",
    "            summary=article.summary,\n",
    "            title=article.title,\n",
    "            text=article.text,\n",
    "        )\n",
    "    return _process_article\n",
    "\n",
    "async def process_article_async(article: Article):\n",
    "    return asyncio.to_thread(process_article, article)\n",
    "\n",
    "async def get_digests_async(term: str, client: NewsApiClient,\n",
    "                      from_param=date.today() - timedelta(days=1),\n",
    "                      language=\"en\"):\n",
    "\n",
    "    response = client.get_everything(term,\n",
    "                      # sources='bbc-news,the-verge,Bloomberg',\n",
    "                      # category='business',\n",
    "                      from_param=from_param,\n",
    "                      language=language)\n",
    "\n",
    "    return await asyncio.gather(\n",
    "        *[process_article_async(Article(article[\"url\"])) for article in response[\"articles\"]]\n",
    "    )\n",
    "\n",
    "async def get_all_digests_async(*terms: str, client: NewsApiClient):\n",
    "    return await asyncio.gather(\n",
    "        *[get_digests_async(term, client) for term in terms]\n",
    "    )\n",
    "\n",
    "# classifier = HappyTextClassification(\n",
    "#     model_type=\"DISTILBERT\", num_labels=2,\n",
    "#     model_name=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "classifier = HappyTextClassification(\n",
    "    model_type=\"BERT\", num_labels=3,\n",
    "    model_name=\"ProsusAI/finbert\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Init pass 9gPj8KZ8XJsLbcT\n",
    "api = NewsApiClient(api_key='98d763c2280d4820913c4abf3ff0270b')\n",
    "\n",
    "# /v2/everything\n",
    "all_articles = api.get_everything(q='bitcoin',\n",
    "                                  # sources='bbc-news,the-verge,Bloomberg',\n",
    "                                  # category='business',\n",
    "                                  from_param=date.today(),\n",
    "                                  language='en')\n",
    "\n",
    "# /v2/top-headlines/sources\n",
    "# sources = api.get_sources()\n",
    "\n",
    "print(f\"Cantidad de articulos: {all_articles['totalResults']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "articles = [{\"title\":article[\"title\"], \"url\":article[\"url\"]} for article in all_articles[\"articles\"]]\n",
    "\n",
    "article = Article(articles[1][\"url\"])\n",
    "\n",
    "digest: Digest = process_article(article)()\n",
    "\n",
    "result = classifier.classify_text(digest.summary)\n",
    "\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "digest.summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}